{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento de Linguagem\n",
    "O Multinomial Naive Bayes é muito utilizado para processamento de linguagem, porém antes de aplicá-lo necessitamos fixar alguns conceitos.\n",
    "\n",
    "O computador trabalha muito bem com processamento de números, mas não com processamento de strings/textos. Para que o algoritmo funcione de maneira correta, precisamos transformar as palavras em números. O método mais simples de executar essa tranformação é criar um vetor/matriz com a contagem de cada palavra presente em nosso corpus.\n",
    "\n",
    "Processo:  \n",
    "Corpus > Tokenization > Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O que é um Corpus?**  \n",
    "Corpus é uma coleção de documentos. No exemplo abaixo temos um corpus com dois documentos (docA e docB):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O gato esta sentado no sofa',\n",
       " 'O cachorro esta sentado no sofa',\n",
       " 'O passarinho esta sentado no poleiro']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de Corpus\n",
    "docA = \"O gato esta sentado no sofa\"\n",
    "docB = \"O cachorro esta sentado no sofa\"\n",
    "docC = \"O passarinho esta sentado no poleiro\"\n",
    "\n",
    "corpus = [docA, docB, docC]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization**  \n",
    "Para poder trabalhar com os documentos, necessitamos seperar cada palavra para que o algoritmo possa interpretá-las, tranformando-as em uma **Bag of words** (saco de palavras). Essa transformação é conhecida como tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['O', 'gato', 'esta', 'sentado', 'no', 'sofa'],\n",
       " ['O', 'cachorro', 'esta', 'sentado', 'no', 'sofa'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de tokenization\n",
    "docA1 = docA.split(\" \")\n",
    "docB1 = docB.split(\" \")\n",
    "\n",
    "# Exibição dos documentos tokenizados\n",
    "docA1, docB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words**  \n",
    "A partir dos documentos tokenizados, podemos tranformá-los em um saco de palavras. O método mais simples é criando um vetor com a contagem de cada palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O', 'cachorro', 'esta', 'gato', 'no', 'sentado', 'sofa'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unindo os dois documentos em palavras únicas\n",
    "wordset = set(docA1).union(set(docB1))\n",
    "wordset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentado': 0, 'sofa': 0, 'cachorro': 0, 'esta': 0, 'no': 0, 'O': 0, 'gato': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um dicionário vazio para a contagem de palavras\n",
    "wordDictA = dict.fromkeys(wordset, 0)\n",
    "wordDictB = dict.fromkeys(wordset, 0)\n",
    "\n",
    "wordDictA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a frequência de cada palavra dos documentos A e B\n",
    "for i in docA1:\n",
    "    wordDictA[i]+=1\n",
    "    \n",
    "for i in docB1:\n",
    "    wordDictB[i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>cachorro</th>\n",
       "      <th>esta</th>\n",
       "      <th>gato</th>\n",
       "      <th>no</th>\n",
       "      <th>sentado</th>\n",
       "      <th>sofa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O  cachorro  esta  gato  no  sentado  sofa\n",
       "0  1         0     1     1   1        1     1\n",
       "1  1         1     1     0   1        1     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando numa matriz de frequência\n",
    "import pandas as pd\n",
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um problema em contarmos cada palavra em nossa bag of words é que palavras muito utilizadas e de pouca importância podem acabar inflenciando o algoritmo. No exemplo acima, palavras como \"o\", \"está\" e \"no\" aparecem mais que as demais e pouco acrescentam à analise.\n",
    "\n",
    "O padrão das línguas naturais seguem a [Lei de Zipf](https://pt.wikipedia.org/wiki/Lei_de_Zipf). Trata-se de uma lei de potências (contrapartida à distribuição gaussiana) sobre a distribuição de valores de acordo com o número de ordem numa lista. Nessa lista, o membro n teria uma relação de valor com o 1º da lista na proporçao 1/n. Isto significa que o segundo elemento se repetirá aproximadamente com uma frequência que é metade da do primeiro, e o terceiro elemento com uma frequência de 1/3 e assim sucessivamente.\n",
    "\n",
    "<img src=\"figuras/Graphique_Zipf_pour_Ulysses.png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "Devido à esse padrão, caso fôssemos analizar um texto grande, talvez não conseguiríamos extrair algum insight valioso, pois preposições e conjuções provavelmente apareceriam mais do que substantivos e adjetivos. Uma abordagem melhor é utilizar o [Tf-Idf](https://pt.wikipedia.org/wiki/Tf%E2%80%93idf), explicado adiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Módulo feature_extraction.text\n",
    "O módulo ``feature_extraction.text`` do Scikit-Learn possui alguns utilitários para construir vetores de recursos numéricos a partir de documentos de texto. Se olharmos dentro do módulo, encontraremos três classes diferentes que podem transformar o texto em recursos numéricos: ``CountVectorizer``, ``HashingVectorizer`` e ``TfidfVectorizer``. A diferença entre eles reside nos cálculos que executam para obter os recursos numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVectorizer**  \n",
    "\n",
    "Basicamente cria um dicionário de palavras a partir do corpus(coleção de documentos). Em seguida, cada instância é convertida em um vetor de recursos numéricos, em que cada elemento será a contagem do número de vezes que uma determinada palavra aparece no documento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "CVect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = CVect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [0, 1, 0, 1, 1, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para verificarmos a contagem de palavras, usamos o .toarray()\n",
    "vector1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cachorro', 'esta', 'gato', 'no', 'passarinho', 'poleiro', 'sentado', 'sofa']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para verificar a que palavra cada coluna pertence, usamos .get_feature_names()\n",
    "CVect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cachorro</th>\n",
       "      <th>esta</th>\n",
       "      <th>gato</th>\n",
       "      <th>no</th>\n",
       "      <th>passarinho</th>\n",
       "      <th>poleiro</th>\n",
       "      <th>sentado</th>\n",
       "      <th>sofa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cachorro  esta  gato  no  passarinho  poleiro  sentado  sofa\n",
       "0         0     1     1   1           0        0        1     1\n",
       "1         1     1     0   1           0        0        1     1\n",
       "2         0     1     0   1           1        1        1     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montando em um DataFrame para melhor vizualização\n",
    "pd.DataFrame(vector1.toarray(), columns=CVect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['esta', 'no', 'passarinho', 'poleiro', 'sentado'], dtype='<U10')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se quisermos olhar as palavras dentro de um documento em específico, utilizamos o .inverse_transform\n",
    "a = vector1.toarray()\n",
    "CVect.inverse_transform(a[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TfidfVectorizer**  \n",
    "Funciona como o CountVectorizer, mas com um cálculo mais avançado chamado Term Frequency Inverse Document Frequency (TF-IDF). Usa uma estatística para medir a importância de uma palavra em um documento ou corpus. Intuitivamente, procura palavras mais frequentes no documento atual, comparadas com a frequência em todo o corpus de documentos. Podemos ver isso como uma maneira de normalizar os resultados e evitar palavras que são muito freqüentes e, portanto, inúteis para caracterizar as instâncias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TfidfVect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo\n",
    "vector2 = TfidfVect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cachorro</th>\n",
       "      <th>esta</th>\n",
       "      <th>gato</th>\n",
       "      <th>no</th>\n",
       "      <th>passarinho</th>\n",
       "      <th>poleiro</th>\n",
       "      <th>sentado</th>\n",
       "      <th>sofa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.469417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.469417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338381</td>\n",
       "      <td>0.572929</td>\n",
       "      <td>0.572929</td>\n",
       "      <td>0.338381</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cachorro      esta      gato        no  passarinho   poleiro   sentado  \\\n",
       "0  0.000000  0.364544  0.617227  0.364544    0.000000  0.000000  0.364544   \n",
       "1  0.617227  0.364544  0.000000  0.364544    0.000000  0.000000  0.364544   \n",
       "2  0.000000  0.338381  0.000000  0.338381    0.572929  0.572929  0.338381   \n",
       "\n",
       "       sofa  \n",
       "0  0.469417  \n",
       "1  0.469417  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Montando em um DataFrame para melhor vizualização\n",
    "pd.DataFrame(vector2.toarray(), columns=TfidfVect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser visto no quadro acima, as palavras 'cachorro', 'gato', 'passarinho' e 'poleiro' tiveram um peso maior que 'sofá', que por sua vez teve um peso maior que 'está', 'no' e 'sentado'. O que o algoritmo fez foi dar um peso maior às palavras que se repetiram menos. Perceba tabmém que na linha 2 as palavras em comum com as demais linhas tiveram um peso diferente, como por exemplo a palavra 'sentado'. Isso ocorreu porque a frase dessa linha possui mais palavras diferentes do que as linhas 0 e 1 (poleiro em vez de sofá)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop words**\n",
    "Como dito anteriormente o texto analisado pode apresentar alta incidência de palavras de pouca relevância (p.ex. artigos, preposições e conjuções) e por mais que atenuemos o peso através da ponderação do TF_IDF, ainda sim pode acabar prejudicando a análise. Uma maneira de diminuir esse problema é utilizando *Stop Words* para retirar essas palavras.  \n",
    "\n",
    "*Stop words* (ou palavras de parada – tradução livre) são palavras que podem ser consideradas irrelevantes para o conjunto de resultados a ser exibido em uma busca realizada em uma search engine. Exemplos: as, e, os, de, para, com, sem, foi.\n",
    "\n",
    "Para utilizar stop words no vectorizer, basta configurar o parâmetro ``stop_words``:\n",
    "\n",
    "    TfidfVectorizer(stop_words='english')\n",
    "\n",
    "Podemos intuir que temos um conjunto de stop words para cada idioma. Se o nosso texto estiver em inglês, basta utilizar o exemplo acima, porém se estiver em portugues teremos que baixar a stop word através do pacote ``nltk``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rildo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')  # baixando as stop words\n",
    "\n",
    "portugues = nltk.corpus.stopwords.words('portuguese')  # escolhendo o idioma português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>um</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>para</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0    de\n",
       "1     a\n",
       "2     o\n",
       "3   que\n",
       "4     e\n",
       "5    do\n",
       "6    da\n",
       "7    em\n",
       "8    um\n",
       "9  para"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando o início da lista\n",
    "pd.DataFrame(portugues).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o parâmetro stop_words no TfidfVectorizer\n",
    "TfidfVect1 = TfidfVectorizer(stop_words=portugues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo\n",
    "vector3 = TfidfVect1.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cachorro</th>\n",
       "      <th>gato</th>\n",
       "      <th>passarinho</th>\n",
       "      <th>poleiro</th>\n",
       "      <th>sentado</th>\n",
       "      <th>sofa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cachorro      gato  passarinho   poleiro   sentado      sofa\n",
       "0  0.000000  0.720333    0.000000  0.000000  0.425441  0.547832\n",
       "1  0.720333  0.000000    0.000000  0.000000  0.425441  0.547832\n",
       "2  0.000000  0.000000    0.652491  0.652491  0.385372  0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo com stop words\n",
    "pd.DataFrame(vector3.toarray(), columns=TfidfVect1.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ao utilizar stop words, as palavras 'esta' e 'no' foram retiradas do vetor e a importância das demais foi aumentada. Com isso o algoritmo pode trabalhar de maneira mais correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cachorro</th>\n",
       "      <th>esta</th>\n",
       "      <th>gato</th>\n",
       "      <th>no</th>\n",
       "      <th>passarinho</th>\n",
       "      <th>poleiro</th>\n",
       "      <th>sentado</th>\n",
       "      <th>sofa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.469417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.469417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338381</td>\n",
       "      <td>0.572929</td>\n",
       "      <td>0.572929</td>\n",
       "      <td>0.338381</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cachorro      esta      gato        no  passarinho   poleiro   sentado  \\\n",
       "0  0.000000  0.364544  0.617227  0.364544    0.000000  0.000000  0.364544   \n",
       "1  0.617227  0.364544  0.000000  0.364544    0.000000  0.000000  0.364544   \n",
       "2  0.000000  0.338381  0.000000  0.338381    0.572929  0.572929  0.338381   \n",
       "\n",
       "       sofa  \n",
       "0  0.469417  \n",
       "1  0.469417  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo sem stop words\n",
    "pd.DataFrame(vector2.toarray(), columns=TfidfVect.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
